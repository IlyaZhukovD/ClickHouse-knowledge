1.  **Введение**

В современном мире многие решения принимаются на основе аналитики над большим объемом данных. Для хранения и обработки такого количества информации используются хранилища, которые отличаются от современных постреляционных субд, таких как postgres, oracle и mysql. Базы данных для обработки аналитических запросов часто не поддерживают требования acid, имеют быстрые операции чтения и вставки. В таких базах данных делается акцент над частыми операциями агрегации, пренебрегая при этом изоляцией во время транзакции и скоростью обновления данных. 

ClickHouse - колоночная olap (online analytical processing) субд с открытым исходным кодом. Изначально база данных проектировалась для использования в веб-аналитике, поскольку стандартные решения на тот момент не поддерживали нагрузку. Позже благодаря своей универсальной архитектуре ClickHouse стал использоваться и в смежных сферах. Например, как система записи логов и метрик, в качестве хранилища исторических данных для ml моделей, а также в системах реального времени для детектирования мошенничества и ботов. 

В силу своих архитектурных особенностей взаимодействие с ClickHouse часто происходит неоптимально и неэффективно. Из-за этого вся система начинает деградировать, пользователи теряют свое время, а для бизнеса это выливается в потерю денег. 

Целью работы является анализ эффективности операций вставки, удаления и обновления данных в ClickHouse. Результат работы -сравнительный анализ существующих подходов управления данными и определение эффективности для каждого из подходов.

Для достижения поставленной цели необходимо решить следующие задачи:

1.  Исследовать процесс вставки данных в таблицы.
2.  Провести экспериментальное сравнение двух стратегий вставки и сформулировать вывод на основе предложенной гипотезы о эффективности каждой из стратегий.
3.  Исследовать основные подходы к удалению данных, проанализировать их ограничения и накладные расходы с точки зрения эффективности.
4.  Исследовать основные подходы к обновлению данных, проанализировать их ограничения и накладные расходы с точки зрения эффективности.

# Основная часть

ClickHouse проектировалась для аналитики над большим объемом данных. Операции вставки, чтение и группировки существенно влияют на производительность всей системы в целом, поэтому архитектура базы данных учитывает эти требования. 

Ключевой особенностью является колоночное хранения данных. Это дает сильное преимущество в операциях агрегации данных по сравнению с традиционными реляционными базами. 

Вторым фактором, который выделяет ClickHouse от конкурентов, является возможность выбирать движок для каждой таблицы. Движок определяет, какие фоновые процессы будут выполняться с этой таблицей. В данной работе будут рассмотрены только движки семейства MergeTree. В их основе лежит структура данных log-structured merge-tree.

Следующая особенность заключается в хранении данных в партах (parts), которые дальше будут использоваться под термином “раздел”. Каждый раздел является физической и логической единицей хранения данных на диске. Раздел представляет собой папку на диске, в которой хранится часть таблицы и метаданные о ней. Каждая операция вставки порождает новый раздел. Далее, в зависимости от типа движка, с каждым разделом происходят фоновые манипуляции. Общая цель фоновых процессов объединить несколько разделов в один. Каждый раздел обладает характеристикой merge level (далее “уровень слияния”). При вставки раздел обладает уровнем 0. Далее в фоне принимается решение объединить несколько разделов. Вследствие чего они объединяются в один раздел. Уровень слияние нового раздела увеличивается на единицу. Старые разделы помещаются как неактивные и удаляются. На рисунке 1 представлена визуализация процесса сляиния. 

<img width="846" height="621" alt="image" src="https://github.com/user-attachments/assets/9fe6a271-2e7b-4f39-bc0e-5cb40d856f45" />

Рисунок 1. Процесс слияния разделов

Четвертая особенность проявляется в том, что данные внутри раздела лежат в отсортированном виде. Это требование оказывает влияние на вставку данных, о которой позже будет описано в разделе по управлению данными во время вставки. Сортировка происходит по ключу или ключам, которые указываются во время создания таблицы.

Хранение данных в сжатом виде. За счет того, что данные колонок лежат рядом, сжатие позволяет сократить место на жестком диске с использованием алгоритмов сжатия без потерь. По умолчанию используется алгоритм LZ4.

Партиция представляет собой логическую единицу группировки данных, которая является совокупностью разделов, имеющих одинаковый ключ партиционирования. 

# 3\. Управление данными: вставка

## 3.1 Описание процесса вставки данных

Рассмотрим стандартный процесс вставка через оператор insert into table.

1.  Получение данных и распаковка, если они были сжаты
2.  Выделение памяти
3.  Сортировка
4.  Сжатие данных
5.  Запись на диск

Как можно видеть накладные расходы на вставку одной строки довольно велики. Согласно документации, рекомендуется вставлять минимум 1000 строк за раз, а лучше 10 000 - 100 000. Это сильно сэкономит ресурсы процессора и диска, поскольку необходимо меньше операций слияния и записи на диск промежуточных разделов. 

Второй аспект, который нужно учитывать во время частой вставки - это количество активных разделов таблицы. У сервера есть системная настройка parts_to_throw_insert, которая по умолчанию равна 3000. Если количество разделов у таблицы становиться больше этой настройки, то при вставке возникает ошибка «Too many parts errors». Эта настройка борется с проблемой фрагментации данных, которая ведет к деградации производительности чтения. Она защищает базу данных от ситуации, когда она принимает данные быстрее, чем физически способна обработать.

Настройка parts_to_throw_insert связана с настройкой part_to_delay_insert, которая по умолчанию равна 1000. Операции вставки останавливаются, если активных разделов больше значения настройки. Она служит такую же роль, как и parts_to_throw_insert, но является первым и более гибким инструментом контроля производительности системы. 

Производительность операции вставки напрямую завязана на количество строк, вставляемых в рамках одной операции. При частой мелкой вставки нагружается ресурс процессора и диска, поскольку перед вставкой данных их необходимо отсортировать и сжать. Настройки part_to_delay_insert и parts_to_throw_insert служат ограничителями для операций вставки, чтобы не привести операции чтения к деградации за счет большого количества файлов, которые надо просканировать. 

## 3.2 Гипотеза для проведения эксперимента

Редкие крупные операции вставки значительно увеличат время вставки и снизят ресурс ввода вывода по сравнению с операциями вставки, которые подразумевают более частую крупную вставку. 

## 3.3 Описание эксперимента

В ходе эксперимента сравним два подхода вставки.

1.  вставка 1000 строк 1 000 000 раз
2.  вставка 1 000 000 строк 1000 раз

Итоговая выборка будет занимать в обоих случаях 1 000 000 000 строк. Вставка будет осуществляться с помощью утилиты clickhouse-benchmark, которая содержится в базовом образе clickhouse версии 25.12.1.91. Вставка в первом опыте будет запущена в 50 потоков, поскольку меньшее количество потоков сильно замедляет эксперимент. 

Вставка будет осуществляться в таблицу случайными данными. Таблица будет содержать 2 столбца типа integer, отсортированных по полю id.

Скрипт создания таблицы.

CREATE TABLE t1 (

&nbsp;   id Int,

&nbsp;   t2_id Int

)

ENGINE=MergeTree()

primary key (id)

ORDER BY id;

## 3.4 Проведение первого опыта

В первом опыте сделаем вставку 1000 строк 1 000 000 раз с помощью скрипта.

clickhouse-benchmark -i 1_000_000 -c 50 -q "INSERT INTO mydb.t1

SELECT number AS id, number % 1000 AS t2_id

FROM numbers(1000);"

#### 3.4.1 Анализ времени вставки и объема данных

Итоговое время вставки составило 20 минут 30 секунд для первого опыта. Обратимся к таблице system.part для того, чтобы проанализировать итоговое количество разделов и их размер на диске. На рисунке 1 можно увидеть разбиение данных по разделам, их объем, а также уровень слияния в столбце level.

<img width="941" height="189" alt="image" src="https://github.com/user-attachments/assets/7a8527e2-ca23-4c8b-be6a-0369d212ce93" />

Рисунок 2. Результат разбиения данных по партам для 1 эксперимента.

Таблица состоит из 5 активных разделов. Уровни разделов сильно варьируются – 45, 29 10, 6 и 1, что говорит большом количестве слияний в процесс вставки. Объем сжатых данных по всем партам – 36058336 байт (34 мб), а несжатых – 8000000000 байт (7.45 гб). 

#### 3.4.2 Анализ утилизации диска

Выведем данные из таблицы system.metric_log по метрике ProfileEvent_OSWriteBytes. Получим объем данных, записанных на диск. Отфильтруем по времени запроса и получим цифру в 51491852288 байт (47.95 гб)
<img width="863" height="314" alt="image" src="https://github.com/user-attachments/assets/96a21124-32e6-4bb1-9d79-e823c82c139f" />

Рисунок 3. Суммарный объем записанных данных на диск для 1 эксперимента.

На рисунке 3 видим, что на жесткий диск было записано 47 гб. Этот показатель говорим о неэффективном использовании ресурса ввода вывода. Объем сохраненных данных от общего объема записанных данных составляет 0,0007 %. 

#### 3.4.3 Анализ влияние настройки part_to_delay_insert

Полученное время вставки можно обосновать параметром part_to_delay_insert, который установлен в 1000. На рисунке 4 можно увидеть, как количество разделов колеблется в районе 1000 штук. Как сказано выше, настройка ограничивает пропускную способность insert операций.
<img width="941" height="283" alt="image" src="https://github.com/user-attachments/assets/0305ac9a-7371-4376-9c88-ea4728c05f19" />

Рисунок 4. Количество разделов в ходе 1 эксперимента при настройке part_to_delay_insert в 1000.

На рисунке 5 можно увидеть график, который соответствует настройке part_to_delay_insert в 2000.  Из графика можно сделать вывод, что настройка действительно выступает в роли ограничителя и замедляет операции вставки. 
<img width="941" height="283" alt="image" src="https://github.com/user-attachments/assets/5057e77e-10b0-473a-b51d-4f0d133b9d78" />

Рисунок 5. Количество разделов в ходе 1 эксперимента при настройке part_to_delay_insert в 2000.

Тем не менее увеличение настройки в ходе эксперимента не принесла глобального вклада в производительность вставки, поскольку только приближала или отдаляла момент замедления. 

Таблица 1. Сводная таблица скорости вставки в зависимости от параметра part_to_delay_insert

|     |     |     |     |
| --- | --- | --- | --- |
|     | part_to_delay_insert = 500 | part_to_delay_insert = 1000 | part_to_delay_insert = 2000 |
| первая минута (строк в секунду) | 1 155 968 | 1 221 491 | 1 321 981 |
| первые 2 минуты (строк в секунду) | 1 153 776 | 1 162 109 | 1 291 100 |
| первые 5 минуты (строк в секунду) | 988 098 | 1 043 273 | 1 149 166 |
| первые 10 минут<br><br>(строк в секунду) | 805 484 | 850 339 | 951 539 |
| первые 15 минут<br><br>(строк в секунду) | 696 944 | 739 324 | 826 484 |

Как видно из таблицы 1, увеличение порога parts_to_delay_insert с 500 до 2000 приводит к умеренному росту средней скорости вставки на всех рассматриваемых интервалах. Так, в первую минуту эксперимента скорость увеличивается примерно с 1,16 млн до 1,32 млн строк/с (+14 %), а к 15‑й минуте: с ~697 тыс. до ~826 тыс. строк/с (около +19 %). При этом во всех трёх конфигурациях заметно постепенное падение производительности по мере увеличения длительности теста: от максимальных значений в первую минуту до существенно более низких к 15‑й минуте (снижение порядка 30–40 % внутри каждой серии измерений). Это указывает на то, что основной фактор деградации - накопление большого количества мелких кусков и рост нагрузки на фоновые слияния, а не конкретное значение порога задержки.

Таким образом, изменение parts_to_delay_insert позволяет сдвинуть момент начала искусственных задержек и немного повысить среднюю скорость вставки, но не устраняет саму природу замедления. Настройка влияет преимущественно на то, когда именно начинается падение производительности, а не на скорость вставки при постоянном потоке мелких вставок.

## 3.5 Проведение второго опыта

Скрипт для вставки 1 000 000 строк 1000 раз

clickhouse-benchmark -i 1000 -d 10  -q "INSERT INTO mydb.t1

SELECT

&nbsp;   number AS id,

&nbsp;   number % 1000 AS t2_id

FROM numbers(1000000);"

#### 3.5.1 Анализ времени вставки и объема данных

Эта операция уже прошла за 23 секунды в один поток. 
<img width="941" height="239" alt="image" src="https://github.com/user-attachments/assets/0c6d2c57-e8ce-4fbe-bb5e-60c4d6c69f33" />

Рисунок 6. Результат разбиения данных по партам для второго опыта.

Обратимся также к таблице system.parts. На рисунке 6 можно увидеть, что объем сжатых данных по всем разделам – 68741972 байт (66 мб), а несжатых также – 8000000000 байт (7.45 гб). 

#### 3.5.2 Анализ утилизации диска

Проанализируем данные из таблицы system.metric_log по метрике ProfileEvent_OSWriteBytes (рисунок 7). Отфильтруем по времени запроса и получим цифру в 6393348096 байт (5.95 гб). Это говорит о том, что ресурса ввода вывода было потрачено в 8 раз меньше по сравнению с первым экспериментом, где этот показатель составил 47.95 гб. 
<img width="941" height="330" alt="image" src="https://github.com/user-attachments/assets/4d715330-29ee-4876-96e0-db1105b94b37" />

Рисунок 7. Суммарный объем записанных данных на диск для 2 эксперимента.

Отношения объема сохраненных данных от общего объема записанных данных составляет составляет 0,01 %. Это значение в 15 раз больше по сравнению с 0,0007% в первом эксперименте.

## 3.6 Итоги эксперимента

Таблица 2. Сводная таблица скорости вставки в зависимости от параметра part_to_delay_insert

|     |     |     |
| --- | --- | --- |
| Характеристика | Первый эксперимент | Второй эксперимент |
| Время вставки (в секундах) | 1230 | 23  |
| Объем данные, записанных на диск (в гб) | 47.95 | 5.95 |
| Процент объема сохраненных данных от общего объема записанных данных на диск | 0,0007 % | 0,01% |

Таким образом, экспериментально подтверждено, что решающим фактором производительности вставки в таблицы семейства MergeTree является размер пакета данных в одной операции INSERT. Для первого опыта совокупное время загрузки 1 млрд строк составило 20,5 минут при объёме записанных на диск данных ~48 ГБ, тогда как при укрупнении пакета вставки до 1 000 000 строк те же 1 млрд строк были загружены за 23 секунды при суммарном объёме записи на диск ~6 ГБ. Отношение полезных данных к общему объёму записи на диск при этом выросло примерно в 15 раз.

## 3.7 Вывод

В итоге главы можно сделать вывод, что частые мелкие вставки приводят к росту числа разделов и объемов фоновых слияний, что выражается в увеличении времени вставки и неэффективном расходовании ресурса ввода вывода. Системная настройка part_to_delay_insert ограничивает рост числа активных разделов и сдвигает момент наступления торможений. Однако не устраняют корневую причину: высокую фрагментацию данных. Параметр part_to_delay_insert следует рассматривать как защитный механизм, а не как основной инструмент оптимизации производительности.

Для высокопроизводительной загрузки данных в сlickhouse необходимо агрегировать записи и использовать крупные пакеты вместо частых мелких вставок.

# 4\. Управление данными: удаление

## 4.1 Описание процесса удаления данных

В таблицах семейства MergeTree операции удаления опираются на свойство формата хранения - данные размещаются в разделах, сгруппированных по партициям. Это означает, что удаление строк превращается либо в удаление целого раздела/партиции, либо в создание нового раздела без удаляемых строк. 

## 4.2 Удаление партиций и разделов

Удаление партиций и разделов является самым дешевым способом освобождения больших объёмов данных. Операция ALTER TABLE … DROP PARTITION приводит к логическому исключению из таблицы всех партиций. С точки зрения запросов на чтение это происходит практически мгновенно. Соответствующие партиции перестают учитываться. Физическое удаление файлов с диска выполняется асинхронно фоновыми потоками. Аналогичным образом работает ALTER TABLE … DROP PART, где удаляется один конкретный раздел. 

Ключевой особенностью удалений на уровне партиций и разделов является отсутствие необходимости переписывать отдельные строки. Фактически меняется только набор используемых папок. Благодаря этому такие операции обладают минимальной нагрузкой на процессор и систему ввода вывода. 

## 4.3 Построчное удаление данных

Построчное физическое удаление предназначено для сценариев, когда необходимо удалить не целые разделы или партиции, а отдельные строки. В архитектуре MergeTree такие операции реализуются через механизм мутаций, который обеспечивает преобразование уже записанных данных в новое состояние. Данный подход имеет две формы: классическую мутацию и легковесное удаление.

### 4.3.1 Удаление через мутацию

Внутри движка удаление организовано как асинхронная мутация данных. После получения команды таблица ставит задачу мутации в очередь, а её непосредственное выполнение производится фоновыми потоками.

Механизм удаления развивается в несколько этапов. 

1.  На первом этапе определяются разделы, которые потенциально содержат строки, удовлетворяющие условию. 
2.  Затем каждый раздел сканируется. Для строк, не подпадающих под условие, формируется новый набор данных, который записывается на диск в виде новых разделов. Параллельно исходный раздел помечается как устаревший. Старые разделы удаляются в фоновом режиме.

Стоит подчеркнуть, что операция является перезаписью значительного объема данных. Это делает классические мутации дорогим инструментом с точки зрения использования процессора и диска. Статус и прогресс таких мутаций можно контролировать через системные таблицы, однако с точки зрения архитектуры следует избегать их частого использования на больших массивах данных.

### 4.3.2 Легковесное удаление

Легковесное удаление реализуется синтаксисом вида DELETE FROM table WHERE &lt;условие&gt; и нацелено на снижение накладных расходов по сравнению с классическими мутациями. Основная идея заключается в том, что при выполнении такой операции данные в существующих разделов не переписываются в формате мутаций. Вместо этого для соответствующих разделов создаются битовые карты, в которых помечаются строки, подлежащие удалению. При последующих запросах на чтение движок учитывает эти структуры данные. Во время чтения таблиц строки, отмеченные в битовой карте как удалённые, исключаются из выборки. Так достигается эффект удаления, при котором в выборке записей нет, хотя физически они присутствуют в разделе.

Физическое удаление происходит во время фоновых операциях слияния. Движок создает новые части уже без строк, помеченных в битовых картах.  

По сравнению с классическим подходом легковесное удаление существенно снижает затраты вычислительных ресурсов на удаление. Вместе с тем оно вводит дополнительные накладные расходы на чтение и не гарантирует немедленного удаления. 

## 4.4 Удаление данные по TTL

Удаление данных по TTL (Time To Live) предоставляет механизм управления жизненным циклом строк. В определении таблицы для столбцов может быть задано выражение TTL, описывающее момент, после которого строка считается устаревшей. Например, правило TTL event_time + INTERVAL 30 DAY DELETE, означающее, что через тридцать дней после значения event_time строка подлежит удалению.

Реализация TTL интегрирована с фоновыми процессами слияния разделов. При каждом слиянии движок анализирует строки в объединяемых частях и вычисляет для них TTL‑условие. Строки, для которых момент жизни уже истек удаляются.

С точки зрения нагрузки на систему подход TTL имеет ряд особенностей. Во‑первых, он обеспечивает равномерное распределение нагрузки по удалению во времени. Во‑вторых, правила TTL задаются один раз в момент проектирования схемы, после чего дальнейшее удаление происходит автоматически. 

Следует учитывать, что механизм TTL неточен. Момент логического наступления срока жизни строки может не совпадать с моментом её физического удаления. Фактическое удаление зависит от частоты фоновых слияний. Поэтому TTL следует рассматривать как инструмент управления жизненным циклом данных с некоторой погрешностью, а не как мгновенный триггер удаления.

## 4.5 Сводная таблица подходов к удалению данных

|     |     |     |     |
| --- | --- | --- | --- |
| Подход | Типичные сценарии применения | Ограничения и особенности | Анализ производительности |
| Удаление партиций и разделов | Удаление устаревших срезов; ручная подчистка частей | Удаляемые данные должны совпадать с границами партиций или разделов; невозможность выборочного удаления отдельных строк внутри части | Логическое удаление практически мгновенно, так как меняется лишь набор используемых файлов; физическое освобождение места выполняется асинхронно; нагрузка на CPU минимальна |
| Классическая мутация | Удаление сравнительно небольших объемов данных | Операция асинхронна и попадает в очередь мутаций | Стоимость операции пропорциональна объёму затронутых данных и числу вовлеченных разделов, так как каждый из них полностью переписывается |
| Легковесное удаление | Удаление сравнительно небольших объемов данных | Физическое освобождение места откладывается до фоновых операций слияний; | Непосредственное выполнение DELETE существенно дешевле классических мутаций, так как не требует переписи разделов; накладные расходы переносятся на чтение и на фоновые слияния; при большом количестве помеченных строк возможна деградация производительности чтения |
| Удаление по TTL | Данные с предсказуемым сроком жизни | Момент физического удаления зависит от интенсивности фоновых слияний; правила TTL должны быть корректно заданы на этапе проектирования | Нагрузка на удаление распределяется во времени и совмещается с обычными операциями слияния; каждая отдельная очистка относительно дешева, но создает постоянный фоновый поток работ. |

## 4.6 Вывод

Операции удаления в сlickhouse опираются на идею неизменяемых разделов, поэтому неизбежно связаны с операциями на уровне файловой структуры. Наиболее производительными являются удаления, работающие с крупными блоками данных. Прежде всего это удаление партиций и отдельных разделов, а также автоматические удаления по TTL. Строчные удаления через мутации и легковесное удаление остаются инструментами для избирательного удаления, однако обладают значительно большей стоимостью, поскольку зависят от объема затронутых разделов.

# 5\. Управление данными: обновление

## 5.1 Описание процесса обновления данных

В таблицах семейства MergeTree операции обновления опираются на то же свойство формата хранения, что и операции удаления. Данные хранятся в неизменяемых разделах, сгруппированных по партициям. Это означает, что непосредственная модификация значения в строчке невозможна. Любое обновление реализуется либо через формирование нового набора разделов с уже измененными значениями и последующее исключение старых частей из чтения, либо через введение дополнительных логических версий поверх физически неизменяемых данных. На практике в ClickHouse можно выделить три основных подхода к обновлению: пересборку данных, строчные физические обновления на основе мутаций и логические обновления на уровне модели данных.

## 5.2 Обновление данных через пересборку таблицы

Обновление через пересборку таблицы является естественным способом реализации массовых изменений, если доля изменяемых данных велика или затрагивается вся таблица. В этом подходе вместо точечного изменения отдельных строк строится новый набор данных, уже содержит все необходимые коррекции, после чего он атомарно подменяет собой исходное состояние.

На уровне всей таблицы такая схема чаще всего реализуется через создание временной таблицы и заполнением ее результатом запроса INSERT INTO new_table SELECT … FROM old_table, в котором применяются все требуемые преобразования. После завершения заполнения старая таблица переименовывается, а временная получает имя рабочей. 

Ключевое преимущество пересборки заключается в том, что операция обновления становится строго последовательной и предсказуемой. Вместо множества локальных преобразований выполняется один или несколько крупных потоковых запросов чтения и записи. При этом стоимость обновления примерно пропорциональна объёму всей перечитываем и перезаписываемой части данных, а не только числу реально изменившихся строк. Поэтому данный подход рационален в сценариях, когда изменение затрагивает существенную долю таблицы.

## 5.3 Строчное физическое обновление 

Строчное физическое обновление данных предназначено для сценариев, когда необходимо модифицировать значения отдельных столбцов в сравнительно небольшом подмножестве строк, не затрагивая структуру таблицы и не пересобирая её целиком. В ClickHouse это реализовано через механизм мутаций, инициируемых командой ALTER TABLE … UPDATE SET … WHERE &lt;условие&gt;.

После приёма такой команды таблица ставит задачу мутации в очередь. Непосредственное ее выполнение осуществляется в фоновом режиме, без блокировки операций чтения и без полной остановки вставок. Движок определяет множество разделов, в которых потенциально находятся строки, попадающие под условие. Для каждого затронутого раздела выполняется чтение его содержимого. Для строк, удовлетворяющих условию, вычисляются новые значения изменяемых столбцов, после чего на диск записывается раздел, уже содержащий обновленные данные. Исходный раздел подлежит удалению.

С точки зрения производительности такой механизм обладает рядом особенностей. Во‑первых, операция выполняется асинхронно и может длиться значительное время при большом объёме затронутых данных. Во‑вторых, вычислительная нагрузка определяется суммарным объёмом разделов, попадающих под условие.

## 5.4 Логическое обновление данных

Логическое обновление данных представляет собой подход, при котором физическое состояние строк в таблице не изменяется, а обновление моделируется на уровне логики запросов и схемы данных. Вместо того чтобы изменять существующую запись, система вставляет новую строку с тем же ключом, но с обновленными значениями и, как правило, с дополнительным признаком актуальности или версионности. Типичным вариантом является введение специальных столбцов, например version, которые позволяют однозначно определить, какая из записей считается актуальной на момент выполнения запроса.

Данный подход обладает важным преимуществом с точки зрения производительности операций записи. Поскольку обновление реализуется как обычная вставка новой строки, оно полностью согласуется с оптимизированной под append‑нагрузку архитектурой MergeTree. Операция вставки остается дешевой, не требует немедленной переработки существующих разделов и не инициирует ресурсоемких мутаций.

Однако логическое обновление переносит часть нагрузки и сложность на сторону хранения и чтения. Во‑первых, объем данных на диске возрастает, поскольку для каждого ключа сохраняются несколько версий записи. Во‑вторых, запросы на чтение вынуждены выполнять дополнительную работу по выбору актуальной версии, что может приводить к увеличению времени выполнения сложных аналитических запросов. В‑третьих, при длительной эксплуатации и большом числе изменений может возникнуть необходимость в периодической физической очистке устаревших версий, реализуемой через пересборку таблицы.

## 5.5 Сводная таблица подходов к обновлению данных

<div class="joplin-table-wrapper"><table><tbody><tr><td><h2><a id="_Toc216768771"></a><a id="_Toc216769448"></a><a id="_Toc216774020"></a>Подход</h2></td><td><h2><a id="_Toc216768772"></a><a id="_Toc216769449"></a><a id="_Toc216774021"></a>Типичные сценарии применения</h2></td><td><h2><a id="_Toc216768773"></a><a id="_Toc216769450"></a><a id="_Toc216774022"></a>Ограничения и особенности</h2></td><td><h2><a id="_Toc216768774"></a><a id="_Toc216769451"></a><a id="_Toc216774023"></a>Анализ производительности</h2></td></tr><tr><td><h2><a id="_Toc216768775"></a><a id="_Toc216769452"></a><a id="_Toc216774024"></a>Пересборка таблицы</h2></td><td><h2><a id="_Toc216768776"></a><a id="_Toc216769453"></a><a id="_Toc216774025"></a>Массовые изменения витрин; корректировка большого процента строк</h2></td><td><h2><a id="_Toc216768777"></a><a id="_Toc216769454"></a><a id="_Toc216774026"></a>Предсказуемое время выполнения</h2></td><td><h2><a id="_Toc216768778"></a><a id="_Toc216769455"></a><a id="_Toc216774027"></a>Стоимость операции пропорциональна объёму всей таблицы; требует дополнительного дискового пространства на период пересборки&nbsp;</h2></td></tr><tr><td><h2><a id="_Toc216768779"></a><a id="_Toc216769456"></a><a id="_Toc216774028"></a>Классическая мутация</h2></td><td><h2><a id="_Toc216768780"></a><a id="_Toc216769457"></a><a id="_Toc216774029"></a>Редкие точечные исправления данных</h2></td><td><h2><a id="_Toc216768781"></a><a id="_Toc216769458"></a><a id="_Toc216774030"></a>Операция асинхронна и попадает в очередь мутаций; при широком условии может охватывать значительную часть таблицы</h2></td><td><h2><a id="_Toc216768782"></a><a id="_Toc216769459"></a><a id="_Toc216774031"></a>Затраты ресурсов определяются суммарным объёмом разделов, попавших под условие; требует полного чтения и переписывания затронутых частей, создавая высокую нагрузку на CPU&nbsp;</h2></td></tr><tr><td><h2><a id="_Toc216768783"></a><a id="_Toc216769460"></a><a id="_Toc216774032"></a>Логическое обновление через дополнительные столбцы&nbsp;</h2></td><td><h2><a id="_Toc216768784"></a><a id="_Toc216769461"></a><a id="_Toc216774033"></a>Высокочастотные обновления; системы с требованием хранить историю изменений</h2></td><td><h2><a id="_Toc216768785"></a><a id="_Toc216769462"></a><a id="_Toc216774034"></a>Требует изменения схемы и логики запросов; объём данных на диске растёт за счёт хранения множества версий;&nbsp;</h2></td><td><h2><a id="_Toc216768786"></a><a id="_Toc216769463"></a><a id="_Toc216774035"></a>Стоимость операции пропорциональна объёму всей таблицы; требует дополнительного дискового пространства на период пересборки&nbsp;</h2></td></tr></tbody></table></div>

## 5.6 Вывод

Эффективность операций обновления зависит от того, сколько данных нужно изменить, какая при этом нагрузка на систему и какой именно способ обновления выбран. Поскольку физическое состояние строк неизменно, любое обновление в итоге сводится либо к перезаписи данных, либо к накоплению логических версий.

Пересборка таблицы оказывается наиболее эффективной при массовых корректировках, когда изменяется значительная часть набора данных. В этом случае один крупный потоковый подход дает предсказуемое время выполнения, хотя и требует дополнительных ресурсов на период пересборки.

Классические мутации оправданы при редких точечных исправлениях.

Логическое обновление через версионность наилучшим образом согласуется с append-ориентированной архитектурой ClickHouse и обеспечивает дешевые, хорошо масштабируемые записи в сценариях высокочастотных изменений. Однако издержки переносятся на чтение.

Таким образом, выбор стратегии должен исходить из профиля нагрузки (частота и доля обновляемых данных), требований к латентности чтения и записи, допустимого роста объема хранения.

# Вывод

Обобщая выводы из разделов, посвящённых вставке, удалению и обновлению данных, можно сделать общий вывод о том, что эффективность и производительность работы ClickHouse определяется не отдельными настройками сервера, а тем, насколько выбранный сценарий использования подстроен под архитектуру семейства MergeTree. Эта архитектура исходит из идеи неизменяемых разделов, которые только добавляются и сливаются в фоновом режиме, а не переписываются по месту. Соответственно, наилучших результатов удаётся добиться тогда, когда прикладные операции формулируются в терминах крупных пакетных вставок, удаления и пересборки целых партиций или их крупных фрагментов, а не как частые строчные изменения, требующие множества дорогостоящих мутаций и перезаписи данных.

# Список источников

1.  Robert Schulze, Tom Schreiber, Ilya Yatsishin - ClickHouse - Lightning Fast Analytics for Everyone // VLDV – 2024 г. – URL https://www.vldb.org/pvldb/vol17/p3731-schulze.pdf
2.  ClickHouse Inc. – Core Concept \[Электронный ресурс\]. — URL: https://clickhouse.com/docs/managing-data/core-concepts
3.  Дейт, К. Дж. Введение в системы баз данных, 8-е издание.: Пер. с англ. — М.: Издательский дом "Вильямс", 2005. — 1328 с
4.  Кузнецов С. Д. Базы данных: учебник для студ. Учреждений высшего проф. Образования / С. Д. Кузнецов. — М.: Издательский центр «Академия», 2012. — 496с.
